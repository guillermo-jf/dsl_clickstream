{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9acaf94-9d37-449b-8d1c-a8286a339901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Project Setup and Configuration\n",
    "# This cell sets up your shell environment with the necessary project configurations and enables the required Google Cloud APIs.\n",
    "\n",
    "# Set your Google Cloud Project ID\n",
    "export PROJECT_ID=\"jellyfish-training-demo-6\"\n",
    "gcloud config set project $PROJECT_ID\n",
    "\n",
    "# Enable necessary APIs\n",
    "gcloud services enable \\\n",
    "  run.googleapis.com \\\n",
    "  pubsub.googleapis.com \\\n",
    "  bigquery.googleapis.com \\\n",
    "  artifactregistry.googleapis.com \\\n",
    "  cloudbuild.googleapis.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b2d22-8b7e-405a-9e6d-45ca24e59d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a location for your container images in Artifact Registry\n",
    "gcloud artifacts repositories create cloud-run-source-repo \\\n",
    "    --repository-format=docker \\\n",
    "    --location=us-central1 \\\n",
    "    --description=\"Docker repository for Cloud Run source\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b5029b-7a9a-4df9-9c4d-3bfb7206d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Write the Python Application Code\n",
    "# This cell contains the updated Python code for our Flask web server. \n",
    "# It now transforms the incoming JSON to match the nested BigQuery schema before insertion.\n",
    "\n",
    "# Save this code in a file named main.py\n",
    "\n",
    "# main.py\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from flask import Flask, request\n",
    "from google.cloud import bigquery\n",
    "\n",
    "app = Flask(__name__)\n",
    "client = bigquery.Client()\n",
    "\n",
    "PROJECT_ID = os.environ.get(\"PROJECT_ID\")\n",
    "BIGQUERY_DATASET = os.environ.get(\"BIGQUERY_DATASET\", \"dsl_project\")\n",
    "BIGQUERY_TABLE = os.environ.get(\"BIGQUERY_TABLE\", \"web_visits\")\n",
    "TABLE_ID = f\"{PROJECT_ID}.{BIGQUERY_DATASET}.{BIGQUERY_TABLE}\"\n",
    "\n",
    "def transform_event(event_item):\n",
    "    \"\"\"Transforms a single event from the source JSON to the BigQuery schema.\"\"\"\n",
    "    event_data = event_item.get(\"event\", {})\n",
    "    event_type = event_data.get(\"event_type\")\n",
    "    details = event_data.get(\"details\", {})\n",
    "\n",
    "    transformed = {\n",
    "        \"event_type\": event_type,\n",
    "        \"event_timestamp\": event_data.get(\"timestamp\"),\n",
    "        \"page_view\": None,\n",
    "        \"add_cart\": None,\n",
    "        \"purchase\": None,\n",
    "    }\n",
    "\n",
    "    if event_type == \"page_view\":\n",
    "        transformed[\"page_view\"] = {\n",
    "            \"page_url\": details.get(\"page_url\"),\n",
    "            \"referrer_url\": details.get(\"referrer_url\"),\n",
    "        }\n",
    "    elif event_type == \"add_item_to_cart\":\n",
    "        transformed[\"add_cart\"] = {\n",
    "            \"product_id\": details.get(\"product_id\"),\n",
    "            \"product_name\": details.get(\"product_name\"),\n",
    "            \"category\": details.get(\"category\"),\n",
    "            \"price\": details.get(\"price\"),\n",
    "            \"quantity\": details.get(\"quantity\"),\n",
    "        }\n",
    "    # Add logic for 'purchase' event type if it exists in your data\n",
    "    # elif event_type == \"purchase\":\n",
    "    #     transformed[\"purchase\"] = { ... }\n",
    "\n",
    "    return transformed\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\"])\n",
    "def index():\n",
    "    \"\"\"Receives and processes a push message from a Pub/Sub subscription.\"\"\"\n",
    "    envelope = request.get_json()\n",
    "    if not envelope or \"message\" not in envelope:\n",
    "        msg = \"invalid Pub/Sub message format\"\n",
    "        print(f\"error: {msg}\")\n",
    "        return f\"Bad Request: {msg}\", 400\n",
    "\n",
    "    message = envelope[\"message\"]\n",
    "    rows_to_insert = []\n",
    "\n",
    "    if \"data\" in message:\n",
    "        data_str = base64.b64decode(message[\"data\"]).decode(\"utf-8\").strip()\n",
    "        for line in data_str.splitlines():\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                events = data.get(\"events\", [])\n",
    "                \n",
    "                if not events:\n",
    "                    continue\n",
    "\n",
    "                # Calculate visit start and end times\n",
    "                timestamps = [e[\"event\"][\"timestamp\"] for e in events if \"timestamp\" in e.get(\"event\", {})]\n",
    "                date_timestamps = [datetime.fromisoformat(ts) for ts in timestamps]\n",
    "                \n",
    "                # Transform events to match BQ schema\n",
    "                transformed_events = [transform_event(e) for e in events]\n",
    "\n",
    "                row = {\n",
    "                    \"session_id\": data.get(\"session_id\"),\n",
    "                    \"user_id\": data.get(\"user_id\"),\n",
    "                    \"device_type\": data.get(\"device_type\"),\n",
    "                    \"geolocation\": data.get(\"geolocation\"),\n",
    "                    \"user_agent\": data.get(\"user_agent\"),\n",
    "                    \"visit_start_time\": min(date_timestamps).isoformat() if date_timestamps else None,\n",
    "                    \"visit_end_time\": max(date_timestamps).isoformat() if date_timestamps else None,\n",
    "                    \"events\": transformed_events,\n",
    "                }\n",
    "                rows_to_insert.append(row)\n",
    "\n",
    "            except (json.JSONDecodeError, ValueError) as e:\n",
    "                print(f\"Error processing line: {e} - Line: '{line}'\")\n",
    "                continue\n",
    "\n",
    "    if not rows_to_insert:\n",
    "        print(\"No rows to insert.\")\n",
    "        return \"Success: No data to process\", 200\n",
    "\n",
    "    errors = client.insert_rows_json(TABLE_ID, rows_to_insert)\n",
    "    if not errors:\n",
    "        print(f\"Successfully inserted {len(rows_to_insert)} rows into {TABLE_ID}\")\n",
    "        return \"Success\", 204\n",
    "    else:\n",
    "        print(f\"Encountered errors while inserting rows: {errors}\")\n",
    "        return f\"Error inserting data: {errors}\", 500\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    PORT = int(os.environ.get(\"PORT\", 8080))\n",
    "    app.run(host=\"0.0.0.0\", port=PORT, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69adcbe8-eae3-42cc-adda-84a85ddba5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt\n",
    "Flask==2.3.2\n",
    "gunicorn==20.1.0\n",
    "google-cloud-bigquery==3.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe57234-92b6-40f7-8302-0efc162e5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create a Dockerfile\n",
    "# This Dockerfile defines the environment for our application. It copies the code, installs dependencies, \n",
    "# and specifies the command to start the Gunicorn server, which is a production-grade WSGI server.\n",
    "\n",
    "# Dockerfile\n",
    "# Use the official lightweight Python image.\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# Set the working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy local code to the container image.\n",
    "COPY . .\n",
    "\n",
    "# Install production dependencies.\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Run the web service on container startup.\n",
    "# Gunicorn is used for production deployment.\n",
    "CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 --timeout 0 main:app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a1fd5-22a2-429c-8880-5fd410f79fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Build and Push the Container Image\n",
    "# This command uses Cloud Build to build our Docker image and push it to the Artifact Registry repository we created in Step 1.\n",
    "\n",
    "# Build the container image using Google Cloud Build\n",
    "gcloud builds submit --tag us-central1-docker.pkg.dev/$PROJECT_ID/cloud-run-source-repo/clickstream-push-bq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c1796-53a2-48b8-bd72-f0dd9f8d36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Deploy the Container to Cloud Run\n",
    "# Now we deploy our container image to Cloud Run. We configure it to be private (--no-allow-unauthenticated) \n",
    "# and pass our BigQuery table details as environment variables.\n",
    "\n",
    "# Deploy the service to Cloud Run\n",
    "gcloud run deploy clickstream-push-bq \\\n",
    "  --image us-central1-docker.pkg.dev/$PROJECT_ID/cloud-run-source-repo/clickstream-push-bq \\\n",
    "  --region us-central1 \\\n",
    "  --no-allow-unauthenticated \\\n",
    "  --set-env-vars=\"PROJECT_ID=$PROJECT_ID,BIGQUERY_DATASET=dsl_project,BIGQUERY_TABLE=web_visits\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f950e16-6e17-4bf2-ba2d-f2c86b93acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Create a Service Account and Grant Permissions\n",
    "# We'll create a dedicated service account for our Pub/Sub subscription to use when invoking the Cloud Run service.\n",
    "\n",
    "# Create a service account for the Pub/Sub subscription\n",
    "gcloud iam service-accounts create pubsub-invoker-sa \\\n",
    "  --display-name=\"Pub/Sub to Cloud Run Invoker\"\n",
    "\n",
    "# Allow the new service account to invoke the Cloud Run service\n",
    "gcloud run services add-iam-policy-binding clickstream-push-bq \\\n",
    "  --member=\"serviceAccount:pubsub-invoker-sa@$PROJECT_ID.iam.gserviceaccount.com\" \\\n",
    "  --role=\"roles/run.invoker\" \\\n",
    "  --region=us-central1\n",
    "\n",
    "# Grant the Cloud Run service's identity the permission to write to BigQuery\n",
    "# This uses the Compute Engine default service account.\n",
    "gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "  --member=\"serviceAccount:$(gcloud projects describe $PROJECT_ID --format='value(projectNumber)')-compute@developer.gserviceaccount.com\" \\\n",
    "  --role=\"roles/bigquery.dataEditor\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad9c780-6d45-456b-87b8-18016d275289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Create the Pub/Sub Push Subscription\n",
    "# Finally, create the push subscription to connect the Pub/Sub topic to our Cloud Run service.\n",
    "\n",
    "# Get the Cloud Run service URL\n",
    "SERVICE_URL=$(gcloud run services describe clickstream-push-bq --platform managed --region us-central1 --format 'value(status.url)')\n",
    "\n",
    "# Create the push subscription\n",
    "gcloud pubsub subscriptions create dsl-clickstream-push-sub \\\n",
    "  --topic dsl-project-clickstream \\\n",
    "  --push-endpoint=$SERVICE_URL \\\n",
    "  --push-auth-service-account=\"pubsub-invoker-sa@$PROJECT_ID.iam.gserviceaccount.com\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d3da3-b1f1-4c2e-9abf-0e673bc71a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Test the Pipeline\n",
    "# Publish a sample message. The test query is updated to UNNEST the events array to verify the nested data.\n",
    "\n",
    "# Publish a sample JSONL message to the topic\n",
    "gcloud pubsub topics publish dsl-project-clickstream --message \\\n",
    "  '{\"session_id\": \"SID-2689\", \"user_id\": \"UID-9529\", \"device_type\": \"desktop\", \"geolocation\": \"44.199851,-171.907106\", \"user_agent\": \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1\", \"events\": [{\"event\": {\"event_type\": \"page_view\", \"timestamp\": \"2025-06-01T09:00:00\", \"details\": {\"page_url\": \"[https://example.com/home](https://example.com/home)\", \"referrer_url\": null}}}, {\"event\": {\"event_type\": \"page_view\", \"timestamp\": \"2025-06-01T09:01:00\", \"details\": {\"page_url\": \"[https://example.com/products](https://example.com/products)\", \"referrer_url\": \"[https://example.com/home](https://example.com/home)\"}}}, {\"event\": {\"event_type\": \"add_item_to_cart\", \"timestamp\": \"2025-06-01T09:02:00\", \"details\": {\"product_id\": \"SFT-004\", \"product_name\": \"Project Manager Plus\", \"category\": \"software\", \"price\": 299.99, \"quantity\": 1}}}]}'\n",
    "\n",
    "# Wait a few moments for processing, then query BigQuery to see the results\n",
    "sleep 10\n",
    "bq query --use_legacy_sql=false \\\n",
    "\"SELECT\n",
    "  session_id,\n",
    "  visit_start_time,\n",
    "  e.event_type,\n",
    "  e.add_cart.product_name,\n",
    "  e.page_view.page_url\n",
    "FROM\n",
    "  \\`$PROJECT_ID.dsl_project.web_visits\\`,\n",
    "  UNNEST(events) AS e\n",
    "WHERE\n",
    "  session_id = 'SID-2689'\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Beam 2.63.0 (Local)",
   "language": "python",
   "name": "apache-beam-2.63.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
